{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Time Series Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from fastdtw import fastdtw\n",
    "from statistics import mean, pstdev\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.spatial.distance import euclidean\n",
    "import pygal\n",
    "import seaborn as sns\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_subdirectories(directory=\"\"):\n",
    "    subdirectories = []\n",
    "    p = Path(\"./../experiments_data/\" + directory)\n",
    "    for item in p.glob('*/'):\n",
    "        if item.suffix not in (['.csv', '.zip']):\n",
    "            subdirectories.append(directory + \"/\" + item.name)\n",
    "    return subdirectories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "all_directories = get_subdirectories()\n",
    "nodes_directories = [x for x in all_directories if \"node\" in x]\n",
    "\n",
    "data_directories = []\n",
    "data_directories_groups = []\n",
    "for directory in nodes_directories:\n",
    "    cur_node_subdirectories = get_subdirectories(directory)\n",
    "    data_directories.append(cur_node_subdirectories)\n",
    "\n",
    "data_directories_groups = data_directories\n",
    "data_directories = [item for sublist in data_directories for item in sublist]\n",
    "\n",
    "function_names = data_directories_groups[1]\n",
    "function_names = list(map(lambda x: x[8:], data_directories_groups[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### All functions in `experiments_data`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- avgNetProfitGroupedBySoldDate\n",
      "- avgNetProfitGroupedBySoldDateWhereProfitNegative\n",
      "- avgNetProfitGroupedBySoldDateWhereYearAfter2000\n",
      "- avgWholeSaleCostGroupedBySoldDate\n",
      "- countDistinctTicketNumber\n",
      "- countNetProfitGroupedBySoldDate\n",
      "- countNetProfitGroupedBySoldDateWhereProfitNegative\n",
      "- countNetProfitGroupedBySoldDateWhereYearAfter2000\n",
      "- countWholeSaleCostGroupedBySoldDate\n",
      "- filterCatalogSalesWhereProfitNegative\n",
      "- filterCatalogSalesWhereProfitNegativeAndYearAfter2000\n",
      "- filterCatalogSalesWhereYearAfter2000\n",
      "- filterStoreSalesWhereProfitNegative\n",
      "- filterStoreSalesWhereProfitNegativeAndYearAfter2000\n",
      "- filterStoreSalesWhereYearAfter2000\n",
      "- maxNetProfitGroupedBySoldDate\n",
      "- maxNetProfitGroupedBySoldDateWhereProfitNegative\n",
      "- maxNetProfitGroupedBySoldDateWhereYearAfter2000\n",
      "- maxWholeSaleCostGroupedBySoldDate\n",
      "- minNetProfitGroupedBySoldDate\n",
      "- minNetProfitGroupedBySoldDateWhereProfitNegative\n",
      "- minNetProfitGroupedBySoldDateWhereYearAfter2000\n",
      "- minWholeSaleCostGroupedBySoldDate\n",
      "- summaryNetProfitGroupedBySoldDate\n",
      "- summaryWholeSaleCostGroupedBySoldDate\n",
      "- sumNetProfitGroupedBySoldDate\n",
      "- sumNetProfitGroupedBySoldDateWhereProfitNegative\n",
      "- sumNetProfitGroupedBySoldDateWhereYearAfter2000\n",
      "- sumWholeSaleCostGroupedBySoldDate\n"
     ]
    }
   ],
   "source": [
    "for function in function_names:\n",
    "    print(f\"- {function[1:]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aggregating labels by functions names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        function_name  \\\n0                       avgNetProfitGroupedBySoldDate   \n1    avgNetProfitGroupedBySoldDateWhereProfitNegative   \n2     avgNetProfitGroupedBySoldDateWhereYearAfter2000   \n3                   avgWholeSaleCostGroupedBySoldDate   \n4                           countDistinctTicketNumber   \n5                     countNetProfitGroupedBySoldDate   \n6   countNetProfitGroupedBySoldDateWhereProfitNega...   \n7   countNetProfitGroupedBySoldDateWhereYearAfter2000   \n8                 countWholeSaleCostGroupedBySoldDate   \n9               filterCatalogSalesWhereProfitNegative   \n10  filterCatalogSalesWhereProfitNegativeAndYearAf...   \n11               filterCatalogSalesWhereYearAfter2000   \n12                filterStoreSalesWhereProfitNegative   \n13  filterStoreSalesWhereProfitNegativeAndYearAfte...   \n14                 filterStoreSalesWhereYearAfter2000   \n15                      maxNetProfitGroupedBySoldDate   \n16   maxNetProfitGroupedBySoldDateWhereProfitNegative   \n17    maxNetProfitGroupedBySoldDateWhereYearAfter2000   \n18                  maxWholeSaleCostGroupedBySoldDate   \n19                      minNetProfitGroupedBySoldDate   \n20   minNetProfitGroupedBySoldDateWhereProfitNegative   \n21    minNetProfitGroupedBySoldDateWhereYearAfter2000   \n22                  minWholeSaleCostGroupedBySoldDate   \n23                      sumNetProfitGroupedBySoldDate   \n24   sumNetProfitGroupedBySoldDateWhereProfitNegative   \n25    sumNetProfitGroupedBySoldDateWhereYearAfter2000   \n26                  sumWholeSaleCostGroupedBySoldDate   \n27                  summaryNetProfitGroupedBySoldDate   \n28              summaryWholeSaleCostGroupedBySoldDate   \n\n                            label  \n0                     aggregation  \n1         aggregation, filtration  \n2   aggregation, filtration, join  \n3                     aggregation  \n4                     aggregation  \n5                     aggregation  \n6         aggregation, filtration  \n7   aggregation, filtration, join  \n8                     aggregation  \n9                      filtration  \n10               filtration, join  \n11               filtration, join  \n12                     filtration  \n13               filtration, join  \n14               filtration, join  \n15                    aggregation  \n16        aggregation, filtration  \n17  aggregation, filtration, join  \n18                    aggregation  \n19                    aggregation  \n20        aggregation, filtration  \n21  aggregation, filtration, join  \n22                    aggregation  \n23                    aggregation  \n24        aggregation, filtration  \n25  aggregation, filtration, join  \n26                    aggregation  \n27                    aggregation  \n28                    aggregation  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>function_name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>avgNetProfitGroupedBySoldDate</td>\n      <td>aggregation</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>avgNetProfitGroupedBySoldDateWhereProfitNegative</td>\n      <td>aggregation, filtration</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>avgNetProfitGroupedBySoldDateWhereYearAfter2000</td>\n      <td>aggregation, filtration, join</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>avgWholeSaleCostGroupedBySoldDate</td>\n      <td>aggregation</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>countDistinctTicketNumber</td>\n      <td>aggregation</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>countNetProfitGroupedBySoldDate</td>\n      <td>aggregation</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>countNetProfitGroupedBySoldDateWhereProfitNega...</td>\n      <td>aggregation, filtration</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>countNetProfitGroupedBySoldDateWhereYearAfter2000</td>\n      <td>aggregation, filtration, join</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>countWholeSaleCostGroupedBySoldDate</td>\n      <td>aggregation</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>filterCatalogSalesWhereProfitNegative</td>\n      <td>filtration</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>filterCatalogSalesWhereProfitNegativeAndYearAf...</td>\n      <td>filtration, join</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>filterCatalogSalesWhereYearAfter2000</td>\n      <td>filtration, join</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>filterStoreSalesWhereProfitNegative</td>\n      <td>filtration</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>filterStoreSalesWhereProfitNegativeAndYearAfte...</td>\n      <td>filtration, join</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>filterStoreSalesWhereYearAfter2000</td>\n      <td>filtration, join</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>maxNetProfitGroupedBySoldDate</td>\n      <td>aggregation</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>maxNetProfitGroupedBySoldDateWhereProfitNegative</td>\n      <td>aggregation, filtration</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>maxNetProfitGroupedBySoldDateWhereYearAfter2000</td>\n      <td>aggregation, filtration, join</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>maxWholeSaleCostGroupedBySoldDate</td>\n      <td>aggregation</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>minNetProfitGroupedBySoldDate</td>\n      <td>aggregation</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>minNetProfitGroupedBySoldDateWhereProfitNegative</td>\n      <td>aggregation, filtration</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>minNetProfitGroupedBySoldDateWhereYearAfter2000</td>\n      <td>aggregation, filtration, join</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>minWholeSaleCostGroupedBySoldDate</td>\n      <td>aggregation</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>sumNetProfitGroupedBySoldDate</td>\n      <td>aggregation</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>sumNetProfitGroupedBySoldDateWhereProfitNegative</td>\n      <td>aggregation, filtration</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>sumNetProfitGroupedBySoldDateWhereYearAfter2000</td>\n      <td>aggregation, filtration, join</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>sumWholeSaleCostGroupedBySoldDate</td>\n      <td>aggregation</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>summaryNetProfitGroupedBySoldDate</td>\n      <td>aggregation</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>summaryWholeSaleCostGroupedBySoldDate</td>\n      <td>aggregation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"./../notebooks/functions.csv\")\n",
    "labels = labels.groupby('function_name')['label'].apply(', '.join).reset_index()\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adding symbols (ts1, ts2, ...) to function names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "iterator = 1\n",
    "symbolic_data = pd.DataFrame(columns=[\"sym\", \"f_name\"])\n",
    "for function in function_names:\n",
    "    symbolic_data = symbolic_data.append({\"sym\": f\"ts{iterator}\", \"f_name\": function[1:]}, ignore_index=True)\n",
    "    iterator += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merging labels with symbols"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# print(\"Legend:\")\n",
    "# labeled_data = pd.merge(symbolic_data, labels, left_on='f_name', right_on='function_name', how='left').drop('function_name', axis=1)\n",
    "# labeled_data = labeled_data\n",
    "# display(labeled_data)\n",
    "# # print(labeled_data['label'].to_string(index=False))\n",
    "# labeled_data.to_csv(f\"./../experiments_data_/preprocessed-data/corr_legend.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grouping labels by UDF type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "agg_labeled = labels.loc[labels[\"label\"] == \"aggregation\"]\n",
    "agg_fil_labeled = labels.loc[labels[\"label\"] == \"aggregation, filtration\"]\n",
    "fil_labeled = labels.loc[labels[\"label\"] == \"filtration\"]\n",
    "agg_fil_join_labeled = labels.loc[labels[\"label\"] == \"aggregation, filtration, join\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def translate_scale(dataframe):\n",
    "    dataframe[\"translated\"] = dataframe['CPU'] - dataframe['CPU'].mean()\n",
    "    dataframe[\"scaled\"] = dataframe[\"translated\"] * (1/dataframe[\"translated\"].std())\n",
    "    return dataframe\n",
    "\n",
    "def dtw_distance(x_labels, y_labels):\n",
    "    distances = []\n",
    "    for x_name in x_labels[\"function_name\"]:\n",
    "        try:\n",
    "            x_data = pd.read_csv(f\"./../experiments_data/preprocessed-data/workers-mean-data/{x_name}/translated_scaled_smoothed_data.csv\")\n",
    "            # print(\"\\n\")\n",
    "            # print(\"------------------------\")\n",
    "            # print(f\"X: {x_name}\")\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "        for y_name in y_labels[\"function_name\"]:\n",
    "            try:\n",
    "                y_data = pd.read_csv(f\"./../experiments_data/preprocessed-data/workers-mean-data/{y_name}/translated_scaled_smoothed_data.csv\")\n",
    "                # distance_scaled, path_scaled = fastdtw(x_data[\"scaled\"], y_data[\"scaled\"], dist=euclidean)\n",
    "                # distance_one_sec, path_one_sec = fastdtw(x_data[\"one_sec\"], y_data[\"one_sec\"], dist=euclidean)\n",
    "                # distance_two_sec, path_two_sec = fastdtw(x_data[\"two_sec\"], y_data[\"two_sec\"], dist=euclidean)\n",
    "                distance_five_sec, path_five_sec = fastdtw(x_data[\"five_sec\"], y_data[\"five_sec\"], dist=euclidean)\n",
    "                distances.append(distance_five_sec)\n",
    "                # distance_ten_sec, path_ten_sec = fastdtw(x_data[\"ten_sec\"], y_data[\"ten_sec\"], dist=euclidean)\n",
    "                # print(f\"Y: {y_name}\")\n",
    "                # print(f\"Scaled: {distance_scaled}\")\n",
    "                # print(f\"1 sec: {distance_one_sec}\")\n",
    "                # print(f\"2 sec: {distance_two_sec}\")\n",
    "                # print(f\"5 sec: {distance_five_sec}\")\n",
    "                # print(f\"10 sec: {distance_ten_sec}\")\n",
    "                # print()\n",
    "            except OSError as e:\n",
    "                print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "    distances.sort()\n",
    "    distances = [i for i in distances if i != 0]\n",
    "    return round(min(distances), 2), round(max(distances), 2), round(mean(distances), 2), round(pstdev(distances), 2), distances,\n",
    "\n",
    "def group_distance_statistics(labels_X, labels_Y, name_X, name_Y, dataframe):\n",
    "    min_value, max_value, mean_value, std_value , all_distances = dtw_distance(labels_X, labels_Y)\n",
    "    dataframe = dataframe.append({\"name\": f\"X:{name_X} Y:{name_Y}\",\n",
    "                                  \"min\": min_value,\n",
    "                                  \"max\": max_value,\n",
    "                                  \"mean\": mean_value,\n",
    "                                  \"std\": std_value,\n",
    "                                  \"distances\": all_distances}, ignore_index=True)\n",
    "    print(\"\\n\")\n",
    "    print(\"----------------------\")\n",
    "    print(f\"{name_X} - {name_Y}\")\n",
    "    print(f\"MIN: {min_value}\")\n",
    "    print(f\"MAX: {max_value}\")\n",
    "    print(f\"MEAN: {mean_value}\")\n",
    "    print(f\"STD: {std_value}\")\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "comparison_statistics = pd.DataFrame(columns=[\"name\", \"min\", \"max\", \"mean\", \"std\", \"distances\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------\n",
      "aggregation - aggregation\n",
      "MIN: 5.68\n",
      "MAX: 130.35\n",
      "MEAN: 37.69\n",
      "STD: 37.53\n",
      "\n",
      "\n",
      "----------------------\n",
      "aggregation - filtration\n",
      "MIN: 178.79\n",
      "MAX: 704.3\n",
      "MEAN: 286.17\n",
      "STD: 103.29\n",
      "\n",
      "\n",
      "----------------------\n",
      "filtration - filtration\n",
      "MIN: 14.61\n",
      "MAX: 14.61\n",
      "MEAN: 14.61\n",
      "STD: 0.0\n",
      "\n",
      "\n",
      "----------------------\n",
      "aggregation - aggregation-filtration\n",
      "MIN: 6.26\n",
      "MAX: 135.3\n",
      "MEAN: 27.31\n",
      "STD: 32.18\n",
      "\n",
      "\n",
      "----------------------\n",
      "filtration - aggregation-filtration\n",
      "MIN: 174.34\n",
      "MAX: 303.04\n",
      "MEAN: 247.42\n",
      "STD: 50.23\n",
      "\n",
      "\n",
      "----------------------\n",
      "aggregation-filtration - aggregation-filtration\n",
      "MIN: 4.02\n",
      "MAX: 9.62\n",
      "MEAN: 6.5\n",
      "STD: 1.78\n",
      "\n",
      "\n",
      "----------------------\n",
      "aggregation - aggregation-filtration-join\n",
      "MIN: 21.36\n",
      "MAX: 142.85\n",
      "MEAN: 40.2\n",
      "STD: 29.8\n",
      "\n",
      "\n",
      "----------------------\n",
      "filtration - aggregation-filtration-join\n",
      "MIN: 210.7\n",
      "MAX: 358.13\n",
      "MEAN: 284.53\n",
      "STD: 70.57\n",
      "\n",
      "\n",
      "----------------------\n",
      "aggregation-filtration-join - aggregation-filtration-join\n",
      "MIN: 5.43\n",
      "MAX: 7.59\n",
      "MEAN: 6.47\n",
      "STD: 0.68\n"
     ]
    }
   ],
   "source": [
    "comparison_statistics = group_distance_statistics(agg_labeled, agg_labeled, \"aggregation\", \"aggregation\", comparison_statistics)\n",
    "comparison_statistics = group_distance_statistics(agg_labeled, fil_labeled, \"aggregation\", \"filtration\", comparison_statistics)\n",
    "comparison_statistics = group_distance_statistics(fil_labeled, fil_labeled, \"filtration\", \"filtration\", comparison_statistics)\n",
    "comparison_statistics = group_distance_statistics(agg_labeled, agg_fil_labeled, \"aggregation\", \"aggregation-filtration\", comparison_statistics)\n",
    "comparison_statistics = group_distance_statistics(fil_labeled, agg_fil_labeled, \"filtration\", \"aggregation-filtration\", comparison_statistics)\n",
    "comparison_statistics = group_distance_statistics(agg_fil_labeled, agg_fil_labeled, \"aggregation-filtration\", \"aggregation-filtration\", comparison_statistics)\n",
    "comparison_statistics = group_distance_statistics(agg_labeled, agg_fil_join_labeled, \"aggregation\", \"aggregation-filtration-join\", comparison_statistics)\n",
    "comparison_statistics = group_distance_statistics(fil_labeled, agg_fil_join_labeled, \"filtration\", \"aggregation-filtration-join\", comparison_statistics)\n",
    "comparison_statistics = group_distance_statistics(agg_fil_join_labeled, agg_fil_join_labeled, \"aggregation-filtration-join\", \"aggregation-filtration-join\", comparison_statistics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "box_plot = pygal.Box(truncate_legend = 25, width = 1000, height = 1000, legend_at_bottom = True, logarithmic=True)\n",
    "box_plot.title = 'Function comparison statistics'\n",
    "for iteration in range(comparison_statistics.shape[0]):\n",
    "    box_plot.add(comparison_statistics.iloc[iteration,0], comparison_statistics.iloc[iteration,5])\n",
    "box_plot.render_to_file(\"chart.svg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# IN dataframe: \"CPU\"\n",
    "# OUT dataframe: \"translated\", \"scaled\", \"one_sec\", \"two_sec\", \"five_sec\", \"ten_sec\"\n",
    "\n",
    "for name in function_names:\n",
    "    file_path = f\"./../experiments_data/preprocessed-data/workers-mean-data{name}\"\n",
    "    original_data = pd.read_csv(f\"{file_path}/mean_data.csv\")\n",
    "    original_data = original_data[[\"CPU\"]]\n",
    "    transformed_data = translate_scale(original_data)\n",
    "    transformed_data[\"one_sec\"] = transformed_data[\"scaled\"].rolling(4, min_periods=1).mean()\n",
    "    transformed_data[\"two_sec\"] = transformed_data[\"scaled\"].rolling(8, min_periods=1).mean()\n",
    "    transformed_data[\"five_sec\"] = transformed_data[\"scaled\"].rolling(20, min_periods=1).mean()\n",
    "    transformed_data[\"ten_sec\"] = transformed_data[\"scaled\"].rolling(40, min_periods=1).mean()\n",
    "    transformed_data.to_csv(f\"{file_path}/translated_scaled_smoothed_data.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ./../experiments_data_/preprocessed-data/workers-mean-data/avgNetProfitGroupedBySoldDateWhereYearAfter2000/translated_scaled_smoothed_data.csv - System nie może odnaleźć określonej ścieżki.\n",
      "Error: ./../experiments_data_/preprocessed-data/workers-mean-data/countNetProfitGroupedBySoldDateWhereYearAfter2000/translated_scaled_smoothed_data.csv - System nie może odnaleźć określonej ścieżki.\n",
      "Error: ./../experiments_data_/preprocessed-data/workers-mean-data/maxNetProfitGroupedBySoldDateWhereYearAfter2000/translated_scaled_smoothed_data.csv - System nie może odnaleźć określonej ścieżki.\n",
      "Error: ./../experiments_data_/preprocessed-data/workers-mean-data/minNetProfitGroupedBySoldDateWhereYearAfter2000/translated_scaled_smoothed_data.csv - System nie może odnaleźć określonej ścieżki.\n",
      "Error: ./../experiments_data_/preprocessed-data/workers-mean-data/sumNetProfitGroupedBySoldDateWhereYearAfter2000/translated_scaled_smoothed_data.csv - System nie może odnaleźć określonej ścieżki.\n"
     ]
    }
   ],
   "source": [
    "# Deleting created files\n",
    "\n",
    "for function_name in function_names:\n",
    "    try:\n",
    "        os.remove(f'./../experiments_data_/preprocessed-data/workers-mean-data{function_name}/translated_scaled_smoothed_data.csv')\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-afd99e2c",
   "language": "python",
   "display_name": "PyCharm (opening-black-box)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}